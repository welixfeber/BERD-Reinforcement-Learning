<!doctype html>
<html>
<head>
  <title>
    Reinforcement Learning for Business, Economics, and Social Sciences Â· 
        Assignment 1
      
  </title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https:&#x2F;&#x2F;BERD-NFDI.github.io&#x2F;BERD-Reinforcement-Learning&#x2F;assets/fonts/assistant/assistant.css">
<link rel="stylesheet" href="https:&#x2F;&#x2F;BERD-NFDI.github.io&#x2F;BERD-Reinforcement-Learning&#x2F;assets/fonts/fa/css/fontawesome.css">
<link rel="stylesheet" href="https:&#x2F;&#x2F;BERD-NFDI.github.io&#x2F;BERD-Reinforcement-Learning&#x2F;assets/fonts/fa/css/solid.css">
<link rel="stylesheet" href="https:&#x2F;&#x2F;BERD-NFDI.github.io&#x2F;BERD-Reinforcement-Learning&#x2F;assets/fonts/fa/css/brands.css">

  <script src="https://cdn.tailwindcss.com?plugins=typography"></script>
<style type="text/tailwindcss">
  html {
  height: 100%;
}

body {
  /* Vertical alignment of <header>, <main> and <footer> */
  height: 100%;
  display: grid;
  grid-template-rows: auto 1fr auto;
}

.prose {
  @apply text-base;
}

.container-width {
  @apply w-full;
}
.container {
  @apply container-width px-6 py-10 lg:px-8;
}
.container-mini {
  @apply mx-auto w-full max-w-3xl;

  .container-escape {
    @apply lg:-ml-40 lg:-mr-40;
  }
}

header {
  font-weight: 500;
}

.prose {
  h1, h2, h3, h4, h5, h6 {
    font-weight: 600;
  }
}
h1{
    @apply text-xl font-semibold my-6;
}
h2{
    @apply text-lg font-semibold my-6;
}
a,button{
    transition:color 0.5s ease;
}
main a{
    position:relative;
    text-decoration: underline;
    text-underline-offset: 8px;
    text-decoration-thickness: 1px;
}


li{
    position:relative;
    margin-left:28px;
    }
li::before{
    content:'\2022';
    position:absolute;
    left:-28px;
    line-height:1.6;
    
}
main > *{
    @apply py-24 px-6 md:px-16 lg:px-24 xl:px-24;
}
/*.padding-all{
@apply px-6 md:px-16 lg:px-24 xl:px-24;
}*/
::selection{
   @apply bg-accent;
   @apply text-primary;
}

 p{
   @apply mb-4 py-0 !important; 
   @apply max-w-[1024px];
}
/*h3:after{
    content:"";
    position:absolute;
    background: white;
    display: block;
    top:0;
    bottom:0;
    width:100vw;
    left:0;
    
    z-index:0;
    
}
h3{
    z-index:1;
}*/
[popover]:not(:popover-open):not(dialog[open]) > div{
    transition:all 0.6s ease;
    transform: translateY(100%);
 
}
[popover] > div{
    transition:all 0.6s ease;
    transform: translateY(0%);
 
}

.inline-arrow {
  width: 18px;
  height: 18px;
  display: inline-block;
  vertical-align: middle;
  text-decoration: none;
}
.invert-logo {
  filter: invert(1);
  -webkit-filter: invert(100%);
}


.block-1c a[href] {
  color: #18bc9c;
}
.block-1c a[href]:hover {
  color: #13967d;
  text-decoration: underline;
}


</style>
<script>
  /** @type {import('tailwindcss').Config} */
tailwind.config = {
  theme: {
    fontSize: {
      xs:'0.75rem',
      sm: '1rem',
      base: '1.5rem', 
      lg: '2rem',
      xl: '2.5rem',
      '2xl': '3rem',
      '3xl': '4rem',
      '4xl':'6rem',
    },
    screens: {
      'sm': '640px',
      'md': '768px',
      'lg': '1024px',
      'xl': '1280px',
      'xxl': '1600px',
      
    },
    extend: {
      fontFamily: {
        sans: ['"Assistant Variable"'],
      },
      colors: {
        primary: '#002c16',
        secondary:'#ffd3e9',
        grey:'#F5F5F5',
        accent:'#ffd3e9',
      },
    },
  },
}

</script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
<script src="https:&#x2F;&#x2F;BERD-NFDI.github.io&#x2F;BERD-Reinforcement-Learning&#x2F;js/lettershuffler.js"></script>
<style>
    .test{
        display:inline-block;
    }
    .test span{
        display:inline-block;
        transform:rotateX(0deg);
        transition:all 0.2s ease;
        color:rgb(255, 211, 233)
    }
     .test span.active{
        transform:rotateX(90deg);
        
    }
</style>

  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
<link rel="icon" type="image/x-icon" href="/favicon.ico">

</head>
<body class="!block">
  
  <header class="fixed w-full z-10 top-0">
    
    <nav class="main-nav mx-auto flex absolute container-width  justify-between  pt-8 lg:pt-10 pb-6  px-6 md:px-16 lg:px-24 xl:px-24" aria-label="Global">
        <a href="https:&#x2F;&#x2F;BERD-NFDI.github.io&#x2F;BERD-Reinforcement-Learning&#x2F;" class="-m-1.5 lg:-ml-9 p-1.5">
            <span class="sr-only">BERD Academy</span>
            
            <span class=" inline-block">
                <img class="inline-block h-12 mb-3" src="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/assets/BERD_academy_logo.png">
                <img class="inline-block h-10 mb-3" src="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/assets/IMG_6635.png">
            </span>
            
        </a>
        <div class="flex lg:hidden">
            <button type="button" popovertarget="global-menu" class="-m-2.5 text-base font-bold inline-flex items-center justify-center rounded-md p-2.5 text-primary hover:text-accent">
                <span class="sr-only">Open main menu</span>
                MENU
                <!--svg class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true">
                <path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
                </svg-->
            </button>
        </div>
        <div class="hidden lg:flex lg:gap-x-12">
            
            
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit1/" class="text-base leading-7 font-semibold text-primary hover:text-accent">
                Unit 1
            </a>
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit2/" class="text-base leading-7 font-semibold text-primary hover:text-accent">
                Unit 2
            </a>
            
            
            <a href="#" class="text-base leading-7 font-semibold text-accent hover:text-accent">
                Assignment 1
            </a>
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit3/" class="text-base leading-7 font-semibold text-primary hover:text-accent">
                Unit 3
            </a>
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit4/" class="text-base leading-7 font-semibold text-primary hover:text-accent">
                Unit 4
            </a>
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/assignment2/" class="text-base leading-7 font-semibold text-primary hover:text-accent">
                Assignment 2
            </a>
            
            
            
            
            
            
        </div>
    </nav>
    <!-- Mobile menu, show/hide based on menu open state. -->
    <div popover id="global-menu" class="bg-transparent" role="dialog" aria-modal="true">
        <div class="fixed flex flex-col items-center justify-center text-center inset-y-0 right-0 z-10 w-full overflow-y-auto bg-grey px-6 py-6 sm:max-w-sm sm:ring-1 sm:ring-gray-900/10">
            <div class="absolute top-4 right-4">

                <button type="button" popovertarget="global-menu" class="-m-2.5 text-base font-semibold rounded-md p-2.5 text-gray-700">
                    <span class="sr-only">Close menu</span>
                    <svg class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12" />
                    </svg>
                </button>
            </div>
            <div class="mt-6 flow-root">
                <div class="-my-6 divide-y divide-gray-500/10">
                    <div class="py-6">
                        
                        
                        
                        
                        
                        <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit1/" class="-mx-3 block rounded-lg  px-4 py-3 text-base leading-7 font-semibold text-gray-900 hover:text-accent">
                            Unit 1
                        </a>
                        
                        
                        
                        
                        <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit2/" class="-mx-3 block rounded-lg  px-4 py-3 text-base leading-7 font-semibold text-gray-900 hover:text-accent">
                            Unit 2
                        </a>
                        
                        
                        
                        
                        <a href="#" class="-mx-3 block rounded-lg  px-4 py-3 text-base leading-7 font-semibold text-accent">
                            Assignment 1
                        </a>
                        
                        
                        
                        
                        <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit3/" class="-mx-3 block rounded-lg  px-4 py-3 text-base leading-7 font-semibold text-gray-900 hover:text-accent">
                            Unit 3
                        </a>
                        
                        
                        
                        
                        <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit4/" class="-mx-3 block rounded-lg  px-4 py-3 text-base leading-7 font-semibold text-gray-900 hover:text-accent">
                            Unit 4
                        </a>
                        
                        
                        
                        
                        <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/assignment2/" class="-mx-3 block rounded-lg  px-4 py-3 text-base leading-7 font-semibold text-gray-900 hover:text-accent">
                            Assignment 2
                        </a>
                        
                        
                        
                        
                        
                        
                    </div>
                    
                </div>
            </div>
        </div>
    </div>
</header>
<div id="float-nav" class="over z-30 fixed w-full top-0 -translate-y-full bg-white transition-all duration-700">
    <nav class=" mx-auto flex relative container-width items-center justify-between  pt-6 pb-6 px-6 md:px-16 lg:px-24 xl:px-24" aria-label="Global">
        <a href="https:&#x2F;&#x2F;BERD-NFDI.github.io&#x2F;BERD-Reinforcement-Learning&#x2F;" class="-m-1.5 lg:-ml-9 p-1.5">
            <span class="sr-only">BERD Academy</span>
            
                <img class="h-8 w-auto" src="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/assets/BERD_academy_logo_green.png" alt="BERD Academy">
            
        </a>
        <div class="flex lg:hidden">
            <button type="button" popovertarget="global-menu" class="text-primary -m-2.5 text-base font-semibold inline-flex items-center justify-center rounded-md p-2.5 ">
                <span class="sr-only">Open main menu</span>
                <!--svg class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true">
                <path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
                </svg-->
                MENU
            </button>
        </div>
        <div class="hidden lg:flex lg:gap-x-12">
            
            
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit1/" class="text-base leading-7 font-semibold  text-primary hover:text-accent">
                Unit 1
            </a>
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit2/" class="text-base leading-7 font-semibold  text-primary hover:text-accent">
                Unit 2
            </a>
            
            
            <a href="#" class="text-base leading-7 font-semibold  text-accent hover:text-accent">
                Assignment 1
            </a>
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit3/" class="text-base leading-7 font-semibold  text-primary hover:text-accent">
                Unit 3
            </a>
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/unit4/" class="text-base leading-7 font-semibold  text-primary hover:text-accent">
                Unit 4
            </a>
            
            
            <a href="https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/assignment2/" class="text-base leading-7 font-semibold  text-primary hover:text-accent">
                Assignment 2
            </a>
            
            
            
            
            
            <a href="https:&#x2F;&#x2F;BERD-NFDI.github.io&#x2F;BERD-Reinforcement-Learning&#x2F;/news" class="text-base leading-7 font-semibold text-white hover:text-primary">News</a>
        </div>
    </nav>
</div>
<script>
  
     var lastScrollTop;
    
       window.onscroll = function() {dropDownMenu();};
    function dropDownMenu(){
        
        if (window.scrollY > document.getElementsByClassName("hero")[0].offsetHeight - 82){
            document.getElementById("float-nav").classList.remove("-translate-y-full");
            //document.getElementById("float-nav").classList.add("translate-y-0");
            console.log("remove");
        }else{
            document.getElementById("float-nav").classList.add("-translate-y-full");
            //document.getElementById("float-nav").classList.remove("translate-y-0");
        }
        
        
    }
</script>


  <!--main class=""><!--class='container'*/-->
</main-->
    


    
        
        
        
    
    
    
    
    
    
        
    

<div
    class="hero text-white flex fixed w-full -z-10 top-0 h-[260px] items-end "
    style="background: url(https://BERD-NFDI.github.io/BERD-Reinforcement-Learning/assets/greenhue_shape_zoom.png);background-size:cover;">
    
    <h1 class="text-xl !font-normal  pt-8 pb-8 px-6 md:px-16 lg:px-24 xl:px-24 m-0">Assignment 1</h1>
    
    
    
    
</div>
<main class="mt-[260px] bg-white z-20 text-base top-0 relative"> 
    <!--div class="-mt-4"-->
        
        <div class="flex items-center justify-center  bg-white w-full px-4 sm:px-8 md:px-16 lg:px-32 mb-12 pb-0" style="height: 25vh;">
    
    <h3 class="text-xl font-bold mb-0 w-full lg:w-4/6 mx-auto text-center">Assignment 1: Multi-Armed Bandit Portfolio</h3>
    
</div>
<p><div  class="relative !p-0"> 
    <div id="assignment-details" class="absolute -top-[80px]">
    </div>
</div>

<div class="flex flex-wrap  bg-white w-full px-4 sm:px-8 md:px-16 lg:px-32 mt-0 mb-0">
    
    <h3 class="text-xl font-bold w-full lg:w-3/5 mx-auto mt-0 mb-0">Assignment Details</h3>
    
    
    <div class="text-[18px] leading-tight w-full lg:w-3/5 mx-auto mt-0 mb-0"><h2 id="introduction">Introduction</h2>
<p>In this project, you will implement Multi-Armed Bandit algorithms. You will use first <em>epsilon-greedy</em> (from lecture) to build a portfolio of stocks adaptively at a daily frequency. Then, you will use <em>Thompson Sampling</em> (from lecture) to compare the performance and some properties of the algorithms.</p>
<p>The code for this project contains the following files, which are available as a <a href="https://github.com/BERD-NFDI/BERD-Reinforcement-Learning/blob/main/content/unit2/assignment_1/assigment%201.zip">zip archive</a>.</p>
<p><strong>Files you'll edit (if you do not want to use Stata but python):</strong></p>
<ul>
<li>
<p><code>bbandit_functions.py</code><br />
Implements batched multi-armed bandit algorithms (epsilon-greedy with decay and Thompson sampling with optional clipping) for updating and simulation.
<br><br>
<strong>Files you should read but NOT edit:</strong></p>
</li>
<li>
<p><code>bbandit_initialize.ado</code><br />
Initializes adaptive experiments.</p>
</li>
<li>
<p><code>bbandit_update.ado</code><br />
Runs adaptive experiments.</p>
</li>
<li>
<p><code>bbandit_sim.ado</code><br />
Runs Monte Carlo simulation of many bandit experiments.</p>
</li>
<li>
<p><code>bbandits.ado</code><br />
Calculates bandit statistics from a dataset.</p>
</li>
</ul>
<p><br><br>
<strong>Files to Edit and Submit:</strong><br />
You will collect data adaptively and generate tables and figures during the assignment. You should submit these files with your code and comments. Please send tables and figures in a single pdf or html, e.g., <code>data.csv</code>, <code>assignment_1_solutions.pdf</code>.<br />
<em>Please do not change the other files in this distribution or submit any of our original files other than these files.</em></p>
<p><strong>Commenting:</strong><br />
In this assignment we ask you to provide extensive commenting on the exhibits (data, tables, and figures, code) you generate. For each exhibit that you implement, provide</p>
<ol>
<li>an overall comment that describes its purpose <strong>and</strong> roughly how it was computed, and</li>
<li>a per-exhibit comment (table or figure notes), describing very briefly what each exhibit is showing.</li>
</ol>
<p>Each per-exhibit comment can simply be a phrase at the end of your exhibit. However, you are also welcome to add separate comment lines. A portion of the project grade (3 points out of 28) will be based on an inspection of your comments in the submitted files.</p>
<p><strong>Stata or Python</strong><br />
EITHER use Stata (easier) OR Python (harder). We will use Python later, so to get an easy start, we recommend Stata. Your choice!</p>
<p><strong>Getting Help</strong><br />
You are not alone! If you find yourself stuck on something, let us know. We want this project to be rewarding and instructional, not frustrating and demoralizing. But we don't know when or how to help unless you ask.</p>
<p><br><br></p>
<h2 id="mab-portfolios">MAB Portfolios</h2>
<p>To get started, collect data on Exchange-Traded Funds (ETFs). ETFs are pooled investment vehicles that trade on stock exchanges much like individual equities. They typically aim to track the performance of a specific index, sector, commodity, or asset class by holding a basket of underlying securities. Build a portfolio of five ETFs with the goal of maximizing total expected profits using Multi-Armed Bandit algorithms. Below are five ETFs across various categories:</p>
<ul>
<li><strong>SPY</strong> seeks to track the performance of the S&amp;P 500 Index, which represents 500 of the largest U.S. companies across all major sectors (e.g., technology, healthcare, financials). It represents large-cap equity.</li>
<li><strong>GLD</strong> is designed to reflect the performance of the price of gold bullion. It owns physical gold stored in secure vaults, so each share represents fractional ownership of actual gold bars. It offers a pure precious-metals play and crisis hedge.</li>
<li><strong>DBC</strong> aims to track the DBIQ Optimum Yield Diversified Commodity Index Excess Return, which holds a diversified basket of physical commodities (e.g., crude oil, gold, natural gas, copper, corn). It invests via futures contracts rather than physical delivery, rolling those contracts monthly.</li>
<li><strong>TIP</strong> gives inflation-linked fixed-income to protect purchasing power over time. It seeks to track the Bloomberg U.S. Treasury Inflation-Protected Securities (TIPS) Index (Series-L), which is composed of U.S. Treasury bonds whose principal adjusts with changes in the Consumer Price Index (CPI).</li>
<li><strong>TLT</strong> seeks to track the ICE U.S. Treasury 20+ Year Bond Index, meaning it invests exclusively in U.S. Treasury bonds with maturities of at least 20 years. A long-duration Treasury position for fixed income to profit if rates fall.</li>
</ul>
<p>You can get daily close prices (adjusted for splits, dividends and distributions) via <code>yfinance</code>.</p>
<p><strong>Note:</strong> Make sure to have a timeline. This is a real-life live experiment!</p>
</div>
</div>

<div  class="relative !p-0"> 
    <div id="q1" class="absolute -top-[80px]">
    </div>
</div>

<div class="flex flex-wrap  bg-grey w-full px-4 sm:px-8 md:px-16 lg:px-32 mt-0 mb-0">
    
    <h3 class="text-xl font-bold w-full lg:w-3/5 mx-auto mt-0 mb-0">Question 1 (5 points): Automatic Portfolio Choice</h3>
    
    
    <div class="text-[18px] leading-tight w-full lg:w-3/5 mx-auto mt-0 mb-0"><p>In each of five trading days, make 200 stock purchases in such a way that your return is maximized. Use the Multi-Armed Bandit algorithm to determine on each of the five days what share of the 200 purchases to allocate to each of the five ETFs. To do this:</p>
<ol>
<li>Set up an initial dataset that specifies a unique identifier for each purchase. Assign the first 200 purchases to batch 1, the second 200 to batch 2, and so on up to batch 5. With an id for 1000 observations, you can use:<pre data-lang="stata" class="language-stata "><code class="language-stata" data-lang="stata">bbandit_initialize , batch(5) arms(5) exploration_phase(0)
</code></pre>
</li>
</ol>
<br>
Giving all ETFs the same chance, set the shares for each arm uniformly in the first batch. That is, set chosen_arm = 1 for the first 40 observations of batch 1, chosen_arm = 2 for the next 40 observations, etc.
<p>Because we havenât observed any rewards yet, the rewards are missing. Use the daily return of the adjusted close prices (corrected for splits, dividends, and distributions) as the success measure. Compute the daily return for day t as:</p>
<p>[
\text{return}<em>t = \frac{\text{Close}</em>{t} - \text{Close}<em>{t-1}}{\text{Close}</em>{t-1}}.
]
On each day, you need to use the previous dayâs closing price to compute the return. At the end of each trading day, record the reward for each purchase and update the allocation using:</p>
<p>bbandit_update reward chosen_arm batch, greedy eps(0.5)
Use epsilon = 1/2 for batch 2, 1/3 for batch 3, 1/4 for batch 4, and 1/5 for batch 5. Comment on better ways to decay epsilon (e.g., polynomial vs. exponential schedules).</p>
<p>The data could look like this:</p>
<p style="text-align:center;"><img src="data.png" alt="data" style="width:700px; height:auto;" /></p>
Grading: We will check your final dataset, code, dates, closing prices, and the resulting shares after five iterations.</div>
</div>
</p>
<p><div  class="relative !p-0"> 
    <div id="q2" class="absolute -top-[80px]">
    </div>
</div>

<div class="flex flex-wrap  bg-white w-full px-4 sm:px-8 md:px-16 lg:px-32 mt-0 mb-0">
    
    <h3 class="text-xl font-bold w-full lg:w-3/5 mx-auto mt-0 mb-0">Question 2 (2 points): Multi-Armed Bandit Statistics</h3>
    
    
    <div class="text-[18px] leading-tight w-full lg:w-3/5 mx-auto mt-0 mb-0"><p>Create the following visualizations:</p>
<p>A histogram showing the shares with which each arm was selected, aggregated over all batches.</p>
<p>A batch-wise line plot of the share (%) of each arm across batches 1 through 5.</p>
<p>This could look like this:</p>
<p style="text-align:center;"><img src="hist.png" alt="histogram" style="width:400px; height:auto;" /><img src="shares_batches.png" alt="shares_batches" style="width:400px; height:auto;" /></p>
Grading: We will check the shares.</div>
</div>
</p>
<p><div  class="relative !p-0"> 
    <div id="q3" class="absolute -top-[80px]">
    </div>
</div>

<div class="flex flex-wrap  bg-grey w-full px-4 sm:px-8 md:px-16 lg:px-32 mt-0 mb-0">
    
    <h3 class="text-xl font-bold w-full lg:w-3/5 mx-auto mt-0 mb-0">Question 3 (1 point): Fixed versus Adaptive versus Best Arm</h3>
    
    
    <div class="text-[18px] leading-tight w-full lg:w-3/5 mx-auto mt-0 mb-0"><p><strong>Compare three portfolio strategies:</strong></p>
<ul>
<li>
<p>A fixed, balanced allocation (20% to each ETF every day).</p>
</li>
<li>
<p>The adaptive Multi-Armed Bandit portfolio allocation from Question 1.</p>
</li>
<li>
<p>The ex-post optimal single ETF (the âbest armâ).</p>
</li>
<li>
<p>Compute the cumulative empirical regret of the Multi-Armed Bandit portfolio relative to both the fixed allocation and the ex-post optimal arm over the five-day period. That is:</p>
</li>
</ul>
<p>[
\mathrm{Regret}<em>T = \sum</em>{t=1}^{T} \bigl(\mathrm{Reward}<em>{\mathrm{optimal},t} - \mathrm{Reward}</em>{\mathrm{MAB},t}\bigr)
]</p>
<p>where Rewardâââ,â is the reward obtained by the best arm in hindsight on day t and Rewardââáµ¦,â is the reward obtained by your MAB portfolio on day t.</p>
<p><strong>Grading: We will check that the regret is correct in each case.</strong></p>
</div>
</div>
</p>
<p><div  class="relative !p-0"> 
    <div id="q4" class="absolute -top-[80px]">
    </div>
</div>

<div class="flex flex-wrap  bg-white w-full px-4 sm:px-8 md:px-16 lg:px-32 mt-0 mb-0">
    
    <h3 class="text-xl font-bold w-full lg:w-3/5 mx-auto mt-0 mb-0">Question 4 (5 points): Thompson Sampling</h3>
    
    
    <div class="text-[18px] leading-tight w-full lg:w-3/5 mx-auto mt-0 mb-0"><p>Convert continuous daily returns into binary rewards by defining:</p>
<p>[
R_t =
\begin{cases}
1, &amp; \text{if daily return}_t \ge 0,\
0, &amp; \text{otherwise.}
\end{cases}
]</p>
<p>Using these binary rewards for the same five-day period, run a Thompson Sampling experiment with the same batches and batch sizes.
Note: Make sure to blind the rewards already obtained with epsilon-greedy.</p>
<p>Compare the resulting portfolio allocations to those from epsilon-greedy. Discuss differences in adaptation speed, concentration on the best arm, and stability.</p>
<p><strong>Grading: We will run your Thompson Sampling algorithm on the same example.</strong></p>
</div>
</div>
</p>
<p><div  class="relative !p-0"> 
    <div id="q5" class="absolute -top-[80px]">
    </div>
</div>

<div class="flex flex-wrap  bg-grey w-full px-4 sm:px-8 md:px-16 lg:px-32 mt-0 mb-0">
    
    <h3 class="text-xl font-bold w-full lg:w-3/5 mx-auto mt-0 mb-0">Question 5 (3 points): Thompson Sampling Simulation</h3>
    
    
    <div class="text-[18px] leading-tight w-full lg:w-3/5 mx-auto mt-0 mb-0"><p>Simulate 20 batches of 1 purchase each (batch(20), size(1)) with Thompson Sampling using true success probabilities of pâ=0.35 and pâ=0.60, no clipping, and plot_thompson and stacked options:</p>
<p>bbandit_sim 0.35 0.60 0.40, size(1) batch(20) clipping(0) thompson plot_thompson stacked
Plot:</p>
<p>The posterior Beta distributions for batch 1 and 20 for each arm.</p>
<p>Comment on what the flat Beta distributions in batch 1 mean and how quickly the algorithm concentrates on the better arm when pâ=0.60.</p>
<p>Hint: The variance of the Beta distribution is:</p>
<p>\mathrm{Var}[\mathrm{Beta}(\alpha,\beta)] = \frac{\alpha,\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}.
The figures could look like this:</p>
<p style="text-align:center;"><img src="ts1.png" alt="ts1" style="width:400px; height:auto;" /><img src="ts20.png" alt="ts20" style="width:400px; height:auto;" /></p>
<p><strong>Grading: We will run your Thompson Sampling algorithm and check results.</strong></p>
</div>
</div>
</p>
<p><div  class="relative !p-0"> 
    <div id="q6" class="absolute -top-[80px]">
    </div>
</div>

<div class="flex flex-wrap  bg-white w-full px-4 sm:px-8 md:px-16 lg:px-32 mt-0 mb-0">
    
    <h3 class="text-xl font-bold w-full lg:w-3/5 mx-auto mt-0 mb-0">Question 6 (4 points): Thompson Sampling Simulation Variations</h3>
    
    
    <div class="text-[18px] leading-tight w-full lg:w-3/5 mx-auto mt-0 mb-0"><br>
Repeat the above simulation under different settings:
<br>
Clipping rates c=0.05 and c=0.45:
<p>bbandit_sim 0.35 0.6, size(20) batch(20) clipping(0.45) thompson 
bbandits reward chosen_arm batch</p>
<p>bbandit_sim 0.35 0.6, size(20) batch(20) clipping(0.05) thompson 
bbandits reward chosen_arm batch
Batch sizes 20 and 100 (with clipping 0.05):</p>
<p>bbandit_sim 0.35 0.60, size(20) batch(20) clipping(0.05) thompson<br />
bbandits reward chosen_arm batch<br />
bbandit_sim 0.35 0.60, size(100) batch(20) clipping(0.05) thompson<br />
bbandits reward chosen_arm batch
Increase the number of batches to 40 (with size 100 and clipping 0.05):</p>
<p>bbandit_sim 0.35 0.60, size(100) batch(40) clipping(0.05) thompson<br />
bbandits reward chosen_arm batch
How do the results differ in terms of:</p>
<p>Convergence speed to the best arm?</p>
<p>Stability of posterior distributions?</p>
<p>Regret over batches?</p>
<p><strong>Grading: We will run your Thompson Sampling algorithm and check accuracy.</strong></p>
</div>
</div>
</p>
<p><div  class="relative !p-0"> 
    <div id="q7" class="absolute -top-[80px]">
    </div>
</div>

<div class="flex flex-wrap  bg-grey w-full px-4 sm:px-8 md:px-16 lg:px-32 mt-0 mb-0">
    
    <h3 class="text-xl font-bold w-full lg:w-3/5 mx-auto mt-0 mb-0">Question 7 (5 points): Non-Stationary Rewards</h3>
    
    
    <div class="text-[18px] leading-tight w-full lg:w-3/5 mx-auto mt-0 mb-0"><p>After batch 10, suppose the true success rate for arm 1 changes (e.g., from 0.35 to 0.90). Modify your Thompson Sampling algorithm to capture this non-stationarity. Possible approaches include:</p>
<p>Using a sliding window on recent rewards to update Beta parameters.</p>
<p>Applying a discount factor Î³ to old observations:</p>
<p>(Î±_k, Î²_k) = (Î³ Î±_k, Î³ Î²_k) +
\begin{cases}
(R_t, 1 â R_t), &amp; \text{if chosen arm} = k,\
(0, 0), &amp; \text{otherwise.}
\end{cases}
Resetting priors after a fixed number of batches.</p>
<p>Implement one of these approaches and demonstrate how the algorithm adapts when arm 1 becomes better after batch 10. Plot the posterior distributions and selection frequencies before and after the change.</p>
<p>Congratulations! You have a learning Portfolio agent!
In order to submit your project, please send the following files: data.csv, assignment_1_solutions.pdf.</p>
</div>
</div>
</p>

        
        
    <!--/div -->
</main>
<script>
    //remove empty <p></p> generated by Zola
     var paragraphs = document.querySelectorAll("main > p");
       for (var i = 0; i < paragraphs.length; i++) {
        if (paragraphs[i].innerHTML==""){
            paragraphs[i].remove();
        }
        
    }
</script>

  
  <footer class="bg-white text-primary py-6 px-6 md:px-16 lg:px-24 xl:px-24 z-40" aria-labelledby="footer-heading">
    <h2 id="footer-heading" class="sr-only">Footer</h2>

    <div class="flex flex-wrap justify-between items-start space-y-4 md:space-y-0"> <!-- flex-wrap added for wrapping -->
        <!-- Contact Information -->
        <div class="flex flex-col md:flex-row md:items-center space-y-4 md:space-y-0 md:space-x-8"> <!-- Column on small screens, row on larger screens -->
            <!-- Email Section -->
            <a href="mailto:berd-academy@stat.uni-muenchen.de" class="flex items-center text-base font-semibold leading-tight hover:text-accent">
                <i class="fas fa-envelope mr-2"></i> <!-- Email icon -->
                berd-academy@stat.uni-muenchen.de
            </a>

            <!-- LinkedIn Section -->
            <a href="https://www.linkedin.com/school/berd-nfdi/" target="_blank" class="flex items-center text-base font-semibold leading-tight hover:text-accent">
                <i class="fab fa-linkedin mr-2"></i> <!-- LinkedIn icon -->
                @berd-nfdi
            </a>
        </div>

        <!-- Footer Links -->
        <div class="flex flex-col md:flex-row space-y-2 md:space-y-0 md:space-x-6"> <!-- Make links wrap and align properly -->
            <a href="/impressum" class="text-base font-semibold leading-tight hover:text-accent">Impressum</a>
        </div>
    </div>

    <!-- Divider -->
    <div class="border-t border-gray-300 mt-6"></div>

    <!-- Footer bottom -->
    <div class="flex justify-between items-center pt-4">
        <p class="text-sm leading-5">&copy; 2025 â BERD Academy. All rights reserved.</p>
    </div>
</footer>


</body>
</html>
